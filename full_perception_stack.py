# -*- coding: utf-8 -*-
"""Full_Perception_Stack.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_mIna7zfB6FL_QJLjzPnA0FPyOzjM_PE
"""

import cv2

from google.colab import drive
drive.mount('/content/drive',force_remount=True)

import os
#os.chdir("/content/drive/MyDrive/drivingstereo")

from google.colab.patches import cv2_imshow
img = cv2.imread('/content/drive/MyDrive/drivingstereo/2018-08-01-11-13-14_r/2018-08-01-11-13-14_2018-08-01-12-04-07-031.png')
img = cv2.resize(img,(880,400),interpolation =cv2.INTER_AREA)
print(img.shape)
cv2_imshow(img)

!git clone https://github.com/mli0603/stereo-transformer

cd stereo-transformer

!pip install -r requirements.txt
!pip install gdown

##### Prepping depth perception ########
import gdown
url = 'https://drive.google.com/uc?id=1UUESCCnOsb7TqzwYMkVV3d23k8shxNcE'
gdown.download(url,'kitti_finetuned_model.pth.tar',quiet=False) 
import torch
if not torch.cuda.is_available():
    print('GPU not available.')
from PIL import Image
import torch
import argparse
import numpy as np
import matplotlib.pyplot as plt
from module.sttr import STTR
from dataset.preprocess import normalization, compute_left_occ_region
from utilities.misc import NestedTensor

# Default parameters
args = type('', (), {})() # create empty args
args.channel_dim = 128
args.position_encoding='sine1d_rel'
args.num_attn_layers=6
args.nheads=8
args.regression_head='ot'
args.context_adjustment_layer='cal'
args.cal_num_blocks=10
args.cal_feat_dim=16
args.cal_expansion_ratio=4

model = STTR(args).cuda().eval()

# Load the pretrained model
model_file_name = "kitti_finetuned_model.pth.tar"
checkpoint = torch.load(model_file_name)
pretrained_dict = checkpoint['state_dict']
model.load_state_dict(pretrained_dict, strict=False) # prevent BN parameters from breaking the model loading
print("Pre-trained model successfully loaded.")
bs = 1
downsample = 3
col_offset = int(downsample / 2)
row_offset = int(downsample / 2)
sampled_cols = torch.arange(col_offset, img.shape[1], downsample).cuda()[None,].expand(bs, -1)
sampled_rows = torch.arange(row_offset, img.shape[0], downsample).cuda()[None,].expand(bs, -1)

object_detect = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True)
object_detect.cuda()

import numpy as np
def get_distance(img, depth, objects):
    df = objects.pandas().xyxy[0]
    print(img.shape,depth.shape)
    df.reset_index() 
    for index, row in df.iterrows():
        print(row['confidence'])
        if row['confidence'] < .35:
            continue
        item = depth[int(row['ymin']):int(row['ymax']),int(row['xmin']):int(row['xmax'])]
        distance = np.average(item)
        print( row['name'], distance)
        #print(int(row['ymin']),int(row['ymax']),int(row['xmin']),int(row['xmax']))
        img = cv2.rectangle(img, (int(row['xmin']),int(row['ymin'])), (int(row['xmax']),int(row['ymax'])), (0, 255, 0), 2)
        text = row['name'] +'-'+ str(round(distance,2)) +'m'
        img = cv2.putText(img,text,(int(row['xmin']),int(row['ymin'])), cv2.FONT_HERSHEY_SIMPLEX, .7,(0, 255, 0),1,cv2.LINE_AA)
    cv2_imshow(img)
    return img

import glob
frames_r = sorted(glob.glob('/content/drive/MyDrive/drivingstereo/2018-08-01-11-13-14_r/*.png'))
frames_l = sorted(glob.glob('/content/drive/MyDrive/drivingstereo/2018-08-01-11-13-14_r/*.png'))
img_r = [cv2.resize(cv2.imread(i),(img.shape[1],img.shape[0]),interpolation =cv2.INTER_AREA) for i in frames_r]
img_l = [cv2.resize(cv2.imread(i),(img.shape[1],img.shape[0]),interpolation =cv2.INTER_AREA) for i in frames_l]

fourcc = cv2.VideoWriter_fourcc(*'mp4v')
output_file = 'output.mp4'
writer = cv2.VideoWriter(output_file, fourcc, 10, (img.shape[1], img.shape[0]))
k=0
for i in range(len(img_l)):
    #input_data = {'left': img_l[i], 'right':img_r[i]}
    #input_data = normalization(**input_data)
    #input_data = NestedTensor(input_data['left'].cuda()[None,],input_data['right'].cuda()[None,], sampled_cols=sampled_cols, sampled_rows=sampled_rows)
    #depth = model(input_data)
    #depth = depth['disp_pred'].data.cpu().numpy()[0]
    #depth_vis = cv2.applyColorMap(np.uint8(depth*10),cv2.COLORMAP_HOT)

    #detected = object_detect(img_r[i])

    #output = get_distance(img_r[i],depth,detected)

    writer.write(img_l[i])
    print(k)
    k+=1

writer.release()